{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Inference Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import text_to_word_sequence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "svm_model_path      = \"artifacts/svm_model.pkl\"\n",
        "rf_model_path       = \"artifacts/random_forest.pkl\"\n",
        "tfidf_path          = \"artifacts/tfidf_vectorizer.pkl\"\n",
        "w2v_path            = \"artifacts/word2vec_model.pkl\"\n",
        "cnn_model_path      = \"artifacts/cnn/cnn_model.keras\"\n",
        "tokenizer_path      = \"artifacts/cnn/tokenizer.pkl\"\n",
        "label_encoder_path  = \"artifacts/cnn/label_encoder.pkl\"\n",
        "\n",
        "svm_model = joblib.load(svm_model_path)\n",
        "rf_model  = joblib.load(rf_model_path)\n",
        "tfidf     = joblib.load(tfidf_path)\n",
        "w2v_model = joblib.load(w2v_path)\n",
        "\n",
        "cnn_model = tf.keras.models.load_model(cnn_model_path)\n",
        "with open(tokenizer_path, \"rb\") as f:\n",
        "    tokenizer = pickle.load(f)\n",
        "with open(label_encoder_path, \"rb\") as f:\n",
        "    le = pickle.load(f)\n",
        "\n",
        "try:\n",
        "    maxlen = cnn_model.input_shape[1] if cnn_model.input_shape[1] else 100\n",
        "except Exception:\n",
        "    maxlen = 100\n",
        "\n",
        "try:\n",
        "    if hasattr(w2v_model, \"wv\"):\n",
        "        vec_size = w2v_model.wv.vector_size\n",
        "        has_wv = True\n",
        "    else:\n",
        "        vec_size = w2v_model.vector_size\n",
        "        has_wv = False\n",
        "except Exception:\n",
        "    vec_size = 300\n",
        "    has_wv = hasattr(w2v_model, \"wv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inference Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def text_to_avg_w2v(texts):\n",
        "    X = np.zeros((len(texts), vec_size), dtype=\"float32\")\n",
        "    for i, t in enumerate(texts):\n",
        "        tokens = text_to_word_sequence(t)\n",
        "        if not tokens:\n",
        "            continue\n",
        "        vecs = []\n",
        "        for tok in tokens:\n",
        "            if has_wv:\n",
        "                if tok in w2v_model.wv:\n",
        "                    vecs.append(w2v_model.wv[tok])\n",
        "            else:\n",
        "                if tok in w2v_model:\n",
        "                    vecs.append(w2v_model[tok])\n",
        "        if vecs:\n",
        "            X[i] = np.mean(vecs, axis=0)\n",
        "    return X\n",
        "\n",
        "def model_predict_with_confidence(model, X):\n",
        "    if X is None:\n",
        "        return None, None, None\n",
        "\n",
        "    if hasattr(model, \"predict_proba\"):\n",
        "        proba = model.predict_proba(X)\n",
        "        preds = proba.argmax(axis=1)\n",
        "        conf  = proba.max(axis=1)\n",
        "        return preds, conf, proba\n",
        "\n",
        "    if hasattr(model, \"decision_function\"):\n",
        "        df = model.decision_function(X)\n",
        "\n",
        "        if np.ndim(df) == 1 or (np.ndim(df) == 2 and df.shape[1] == 1):\n",
        "            df = np.ravel(df)\n",
        "            preds = (df >= 0).astype(int)\n",
        "\n",
        "            conf  = 1.0 / (1.0 + np.exp(-np.abs(df)))\n",
        "            return preds, conf, None\n",
        "        else:\n",
        "  \n",
        "            df = np.asarray(df)\n",
        "            e = np.exp(df - df.max(axis=1, keepdims=True))\n",
        "            soft = e / e.sum(axis=1, keepdims=True)\n",
        "            preds = soft.argmax(axis=1)\n",
        "            conf  = soft.max(axis=1)\n",
        "            return preds, conf, None\n",
        "\n",
        "    preds = model.predict(X)\n",
        "    conf  = np.full(len(preds), np.nan)\n",
        "    return preds, conf, None\n",
        "\n",
        "def choose_feature_space_and_predict(model, texts, X_tfidf, X_w2v):\n",
        "    n_in = getattr(model, \"n_features_in_\", None)\n",
        "\n",
        "    if X_tfidf is not None and (n_in is None or X_tfidf.shape[1] == n_in):\n",
        "        p, c, _ = model_predict_with_confidence(model, X_tfidf)\n",
        "        if p is not None:\n",
        "            return p, c, \"tfidf\"\n",
        "\n",
        "    if X_w2v is not None and (n_in is None or X_w2v.shape[1] == n_in):\n",
        "        p, c, _ = model_predict_with_confidence(model, X_w2v)\n",
        "        if p is not None:\n",
        "            return p, c, \"w2v\"\n",
        "\n",
        "    p, c, _ = model_predict_with_confidence(model, X_tfidf)\n",
        "    if p is not None:\n",
        "        return p, c, \"tfidf\"\n",
        "    p, c, _ = model_predict_with_confidence(model, X_w2v)\n",
        "    if p is not None:\n",
        "        return p, c, \"w2v\"\n",
        "\n",
        "    return None, None, \"unknown\"\n",
        "\n",
        "def map_to_label_names(y_pred):\n",
        "    if y_pred is None:\n",
        "        return None\n",
        "    try:\n",
        "        arr = np.array(y_pred)\n",
        "        if np.issubdtype(arr.dtype, np.integer) and hasattr(le, \"classes_\"):\n",
        "            if len(le.classes_) >= (np.max(arr) + 1):\n",
        "                return le.inverse_transform(arr)\n",
        "        return y_pred\n",
        "    except Exception:\n",
        "        return y_pred\n",
        "\n",
        "def safe_round(x, n=4):\n",
        "    return np.round(x, n) if x is not None else None\n",
        "\n",
        "texts = [\n",
        "    \"Filmnya bagus banget, aktingnya memukau dan ending-nya memuaskan!\",\n",
        "    \"Pelayanannya buruk, pesanan terlambat dan rasanya mengecewakan.\",\n",
        "    \"Saya baru selesai menonton film itu, akan coba baca ulasannya nanti.\"\n",
        "]\n",
        "\n",
        "X_tfidf = tfidf.transform(texts)\n",
        "X_w2v   = text_to_avg_w2v(texts)\n",
        "\n",
        "svm_preds_raw, svm_conf, svm_used = choose_feature_space_and_predict(svm_model, texts, X_tfidf, X_w2v)\n",
        "rf_preds_raw,  rf_conf,  rf_used  = choose_feature_space_and_predict(rf_model,  texts, X_tfidf, X_w2v)\n",
        "\n",
        "svm_labels = map_to_label_names(svm_preds_raw)\n",
        "rf_labels  = map_to_label_names(rf_preds_raw)\n",
        "\n",
        "seqs = tokenizer.texts_to_sequences(texts)\n",
        "pads = pad_sequences(seqs, maxlen=maxlen, padding=\"post\")\n",
        "cnn_raw = cnn_model.predict(pads, verbose=0)\n",
        "\n",
        "if cnn_raw.ndim == 1 or (cnn_raw.ndim == 2 and cnn_raw.shape[1] == 1):\n",
        "    cnn_conf  = cnn_raw.ravel()\n",
        "    cnn_preds = (cnn_conf >= 0.5).astype(int)\n",
        "else:\n",
        "    cnn_conf  = cnn_raw.max(axis=1)\n",
        "    cnn_preds = cnn_raw.argmax(axis=1)\n",
        "\n",
        "cnn_labels = le.inverse_transform(cnn_preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inference Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "G_Yo2pU2D5Dy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                text svm_pred  svm_conf svm_feat  rf_pred  rf_conf rf_feat cnn_pred  cnn_conf\n",
            "   Filmnya bagus banget, aktingnya memukau dan ending-nya memuaskan! positive    0.7836    tfidf positive   0.9547     w2v positive     1.000\n",
            "     Pelayanannya buruk, pesanan terlambat dan rasanya mengecewakan. negative    0.7566    tfidf negative   0.4840     w2v negative     1.000\n",
            "Saya baru selesai menonton film itu, akan coba baca ulasannya nanti. positive    0.7696    tfidf positive   0.6330     w2v positive     0.999\n"
          ]
        }
      ],
      "source": [
        "df = pd.DataFrame({\n",
        "    \"text\": texts,\n",
        "    \"svm_pred\": svm_labels if svm_labels is not None else [\"<failed>\"]*len(texts),\n",
        "    \"svm_conf\": safe_round(svm_conf),\n",
        "    \"svm_feat\": [svm_used]*len(texts),\n",
        "    \"rf_pred\":  rf_labels if rf_labels is not None else [\"<failed>\"]*len(texts),\n",
        "    \"rf_conf\":  safe_round(rf_conf),\n",
        "    \"rf_feat\":  [rf_used]*len(texts),\n",
        "    \"cnn_pred\": cnn_labels,\n",
        "    \"cnn_conf\": safe_round(cnn_conf),\n",
        "})\n",
        "\n",
        "pd.set_option(\"display.max_colwidth\", 200)\n",
        "print(df.to_string(index=False))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env310",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
